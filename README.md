# ğŸ§  OpenAI GPT 4 / 4o / 5 / 5.1 / 5-Pro Manifold for OpenWebUI

### Advanced Responses-API Router â€¢ Reasoning Engine â€¢ Image Support â€¢ Cost Tracking â€¢ Web Search â€¢ MCP â€¢ Tools

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![OpenWebUI](https://img.shields.io/badge/OpenWebUI-Compatible-success)
![OpenAI](https://img.shields.io/badge/OpenAI-Responses_API-red)

A **fully custom, heavily-modified** OpenAI Responses-API manifold for OpenWebUI supporting:

âœ” GPT-4
âœ” GPT-4o (4o, 4o-mini, 4o-reasoning)
âœ” GPT-5
âœ” GPT-5.1
âœ” GPT-5-Pro
âœ” gpt-image-1
âœ” o-series reasoning models
âœ” MCP tools
âœ” Web search preview
âœ” Full cost accounting for tokens + images
âœ” Pseudo models for high-effort reasoning

Built on top of:
[https://github.com/jrkropp/open-webui-developer-toolkit/tree/main/functions/pipes/openai_responses_manifold](https://github.com/jrkropp/open-webui-developer-toolkit/tree/main/functions/pipes/openai_responses_manifold)
â€¦but **heavily expanded**, re-architected, optimized, and enhanced.

---

# ğŸš€ Features

Below is a **complete feature breakdown** of everything this manifold does.

---

# 1. OpenAI Responses API Bridge for OpenWebUI

* Converts WebUI-style requests â†’ **OpenAI Responses API** format.
* Normalizes model names and strips `openai_responses.` prefix.
* Injects an identity preamble so when users ask *â€œwhat model are you?â€*, the answer reflects the **WebUI-visible pseudo model**:

  * Example: `gpt-5-thinking-high`, `gpt-5-auto`, etc.

---

# 2. Model Routing, Pseudo-Models & Reasoning Effort

Supports an extensive set of **pseudo models** that map to real OpenAI models with reasoning settings:

| Pseudo Model          | Actual Model | Effort |
| --------------------- | ------------ | ------ |
| gpt-5-thinking        | gpt-5        | medium |
| gpt-5-thinking-high   | gpt-5        | high   |
| gpt-5.1-thinking-high | gpt-5.1      | high   |
| o3-mini-high          | o3-mini      | high   |
| o4-mini-high          | o4-mini      | high   |

### gpt-5-auto Router

* Automatically chooses a best-fit model.
* Applies reasoning levels based on your rules.

### GPT-5-Pro Special Handling

* Forced `effort="high"`
* Non-streaming only (due to API restrictions)

---

# 3. Reasoning Features & Summaries

### Supported Features

* `reasoning.effort`
* `reasoning.summary` (visible chain-of-thought summaries)

### Summary Valve

`REASONING_SUMMARY = auto | concise | detailed | disabled`

### Persisted Reasoning Tokens Valve

`PERSIST_REASONING_TOKENS = disabled | response | conversation`

Allows OpenAI to carry encrypted reasoning forward.

### UI Integration

* Uses `<details>` blocks to create:

  * **Thinkingâ€¦**
  * reasoning summary
  * **Done thinking!**

Clean, collapsible, fully readable without polluting main output.

---

# 4. Tools, Web Search, and MCP

### Function Calling

* Converts WebUI tools â†’ **strict** Responses-API JSON schemas.
* If native function calling is disabled in WebUI, the manifold:

  * Automatically patches the model config
  * Displays a toast message instructing user to retry

### Web Search (web_search_preview)

Enabled when:

* Model supports it (4.1, 4o, o-series)
* Valve on
* Effort â‰  minimal

Provides:

* Context size tuning
* Optional user location
* URL tracking + numbered citations
* Source panel events

### MCP Integration

Automatically loads all MCP servers defined in:

```
REMOTE_MCP_SERVERS_JSON
```

---

# 5. Image Support (Input + Generation)

### 5.1 Image Input (User â†’ Model)

All WebUI content blocks are converted:

| WebUI      | Responses API |
| ---------- | ------------- |
| text       | input_text    |
| image_url  | input_image   |
| input_file | input_file    |

### 5.2 Image Generation (Model â†’ User)

* Detects `image_generation_call`
* Displays: **â€œğŸ¨ Let me create that imageâ€¦â€**
* Tracks generated images
* Estimates image count when OpenWebUI hides tool calls

---

# 6. Cost Estimation System (Tokens + Images)

### 6.1 Built-in Pricing

#### Token Pricing

Supports:

* GPT-5, GPT-5.1, GPT-5-Pro
* GPT-4.1, 4.1-mini, 4.1-nano
* GPT-4o text

#### Image Pricing

* `gpt-image-1` @ 1024Ã—1024 â†’ **$0.04 per image**

---

### 6.2 Per-Conversation Cost Tracking

* Local session DB maintains cumulative totals by `chat_id`
* Each assistant turn:

  * Summarizes cost
  * Updates cumulative totals
  * Displays inline or toast cost depending on settings

---

### 6.3 Cost Valves

| Valve                   | Behavior                                 |
| ----------------------- | ---------------------------------------- |
| SHOW_COSTS              | Enables or disables cost system entirely |
| INCLUDE_IMAGE_COSTS     | Token-only or token+image pricing        |
| INLINE_COSTS_IN_MESSAGE | Inline or toast display                  |

### Example Cost Output

```
[approx cost this reply (gpt-5-thinking-high â†’ gpt-5): $0.00019 | approx total: $0.00019]
```

### Deduplication

Automatically removes old cost lines to prevent stacking.

---

### 6.4 Image Cost Inference

If WebUI hides image API calls, the manifold:

* Analyzes assistant text
* Infers image generation
* Applies default pricing

Example:
If output text says *â€œHere is your generated imageâ€*, cost system infers `1 image`.

---

# 7. Message & History Handling

* Persists hidden items (tool calls, reasoning, images)
* Embeds invisible markers in messages
* Re-hydrates previous items into `input[]` for multi-turn continuity

---

# 8. Verbosity Control

Reactively adjusts output length:

| User Message   | Effect           |
| -------------- | ---------------- |
| â€œAdd detailsâ€  | verbosity = high |
| â€œMore conciseâ€ | verbosity = low  |

Automatically removes the trigger message and regenerates the response.

---

# ğŸ“¦ Installation

### 1. Navigate to your OpenWebUI directory:

```
~/.config/open-webui/pipes
```

### 2. Add the manifold

Place your file here:

```
openai_responses_manifold_gpt51_pro_v21.py
```

### 3. Restart OpenWebUI

The pipeline will load automatically.

---

# âš™ï¸ Optional: OpenWebUI Model Config Template

Example model entry:

```json
{
  "name": "gpt-5-thinking-high",
  "id": "openai_responses.gpt-5-thinking-high",
  "provider": "openai_responses",
  "mode": "chat",
  "native_tools": true,
  "native_tool_calling": true
}
```

---

# ğŸ§© File Structure (Diagram)

```
openai_responses_manifold/
â”‚
â”œâ”€â”€ model_aliases/        # Pseudo model â†’ real model logic
â”œâ”€â”€ routers/              # gpt-5-auto selection logic
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ markers.py        # Hidden item marker system
â”‚   â”œâ”€â”€ costs.py          # Pricing + cost generation
â”‚   â”œâ”€â”€ items.py          # Persistence + rehydration
â”‚   â””â”€â”€ messages.py       # Transformer for WebUI â†’ Responses API
â”‚
â””â”€â”€ manifold.py           # Main pipeline implementation
```

*(Directory names for illustration â€” adapt based on your actual layout.)*

---

# ğŸ§ª Sample Usage

Ask a deep reasoning question:

```
Explain GÃ¶delâ€™s incompleteness theorem in the style of a physics textbook.
```

Request an image:

```
Generate a cyberpunk cityscape at night with neon fog.
```

Enable high reasoning:

```
Use high reasoning effort for the next answer.
```

Ask to expand detail:

```
Add details
```

---

# ğŸ“ License

MIT License â€“ free to modify and redistribute.

---

# â¤ï¸ Acknowledgements

* Original manifold by **@jrkropp**
* Extended & upgraded into a full multi-model, multi-system router
* Designed specifically for developers using **OpenWebUI + OpenAI Responses API**

---
